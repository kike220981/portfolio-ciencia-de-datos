{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import sqlite3\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.tree import DecisionTreeRegressor, plot_tree\n",
    "from sklearn import linear_model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "import statsmodels.api as sm\n",
    "import dtreeviz\n",
    "import matplotlib.font_manager\n",
    "import scipy as sp\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(os.getcwd())\n",
    "os.chdir('./../')\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuraciones\n",
    "# ------------------------------------------------------\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.options.display.float_format = '{:.2f}'.format\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "plt.style.use(\"seaborn-v0_8-whitegrid\")\n",
    "plt.rc(\"figure\", autolayout=True, figsize=(11, 5))\n",
    "plt.rc(\n",
    "    \"axes\",\n",
    "    labelweight=\"bold\",\n",
    "    labelsize=\"large\",\n",
    "    titleweight=\"bold\",\n",
    "    titlesize=14,\n",
    "    titlepad=10,\n",
    ")\n",
    "plot_params = dict(\n",
    "    markeredgecolor=\"0.25\",\n",
    "    markerfacecolor=\"0.25\",\n",
    "    legend=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Funciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def metricas_evaluacion(y_test, y_pred, printed=True):\n",
    "    if printed:\n",
    "        print('Mean Absolute Error:', metrics.mean_absolute_error(y_test,y_pred))\n",
    "        print('Mean Squared Error:', metrics.mean_squared_error(y_test, y_pred))\n",
    "        print('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(y_test,y_pred)))\n",
    "        print('r2_score:', metrics.r2_score(y_test,y_pred))\n",
    "        print('MAPE:', metrics.mean_absolute_percentage_error(y_test,y_pred))\n",
    "        return None\n",
    "    else:\n",
    "        return metrics.mean_absolute_error(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_train_test_predict(y_train, y_test, y_pred):\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(7, 4))\n",
    "    y_train.plot(**plot_params, ax=ax, color='blue', alpha=0.5, label='Train')\n",
    "    y_test.plot(**plot_params, ax=ax, color='grey', alpha=0.5, label='Test')\n",
    "    y_pred = pd.Series(y_pred, index=y_test.index)\n",
    "    y_pred.plot(**plot_params, ax=ax, color='r', label='Predict')\n",
    "    mae = metricas_evaluacion(y_test, y_pred, printed=False)\n",
    "    fig.suptitle(f\"Predicción de uso de bicicletas, MAE {mae:.2f}\")\n",
    "    plt.legend(loc=0)\n",
    "    plt.xticks(rotation=70)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Carga de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./data/processed/usobarriosmeteo.csv')\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['fecha'] = pd.to_datetime(df['fecha'])\n",
    "df.sort_values('fecha', inplace=True)\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.loc[df['name']=='EL CARME'].copy()\n",
    "df.sort_values('fecha', inplace=True)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Separar train test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.loc[:, ['hora', 'dia']]\n",
    "y = df['uso_bici']\n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_split = train_test_split(X, y, random_state=22, shuffle=False)\n",
    "X_train, X_test, y_train, y_test = res_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(7, 4))\n",
    "ax.plot(X_train.index, y_train)\n",
    "ax.plot(X_test.index, y_test)\n",
    "fig.suptitle(\"Uso de bicicletas por estación\")\n",
    "plt.xticks(rotation=70)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = np.ones_like(y_test)\n",
    "y_pred.fill(y_train.mean())\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metricas_evaluacion(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(7, 4))\n",
    "ax.plot(X_train.index, y_train)\n",
    "ax.plot(X_test.index, y_test)\n",
    "ax.axhline(y_train.mean(), color='r')\n",
    "fig.suptitle(\"Uso de bicicletas por estación\")\n",
    "plt.xticks(rotation=70)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aprendizaje supervisado para el modelado del uso de bicis\n",
    "\n",
    "Variable que queremos modelar el comportamiento se le denomina variable de salida, respuesta, endógena o y.\n",
    "\n",
    "Variable o conjunto de variables que se relacionan con la respuesta son variables de entrada, predictoras, explicativas, regresores, exógenas, o x_i\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Árboles de decisión\n",
    "\n",
    "Son un conjunto de reglas ordenadas en forma de árbol jerárquico. Se aplica en aprendizaje supervisado.\n",
    "\n",
    "Este árbol puede construirse de forma automática como parte de un proceso de aprendizaje automático a partir de datos.\n",
    "\n",
    "El árbol está compuesto por la raíz, ramas, nodos y hojas:\n",
    "- Raíz: nodo inicio o condición incial de un árbol.\n",
    "- Nodo: condición establecida.\n",
    "- Rama: respuesta a la condición aplicada en el nodo antecedente.\n",
    "- Hoja: Fin del recorrido del árbol donde se define la decisión final\n",
    "\n",
    "Las reglas pueden describirse como condiciones simples en base a un atributo o característica:\n",
    "- Es fin de semana.\n",
    "- La lluvia es mayor o igual.\n",
    "- Hora es mayor de las 9 y menor o igual a 16 horas.\n",
    "\n",
    "El cumplimiento o no de la condición hará que para tomar una decisión se deba recorrer una u otra rama (exhaustivo).\n",
    "\n",
    "El recorrido de una rama completa concluye con el nodo hoja donde se toma la decisión final.\n",
    "\n",
    "Esta decisión puede ser de tipo clasificación, etiqueta o nominal (disjuntas); o puede ser regresión, numérica o continua.\n",
    "\n",
    "Existen varios algoritmos de partición para la creación de estos árboles: ID3, C4.5, CART, etc.\n",
    "\n",
    "El árbol sólo aporta una solución, por tanto, las particiones deben ser exhaustivas y excluyentes.\n",
    "\n",
    "El criterio de partición y el número de particiones son los parámetros a ajustar, en estos algoritmos, entre otros.\n",
    "\n",
    "Debemos de tener en cuenta, como criterios, la expresividad de nuesto árbol y la complejidad para evitar sobre ajustes.\n",
    "\n",
    "[Implementación en Scikit-Learn](https://scikit-learn.org/stable/modules/tree.html#tree-algorithms-id3-c4-5-c5-0-and-cart)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_reg = DecisionTreeRegressor(max_depth=2)\n",
    "tree_reg.fit(X_train[['hora']], y_train)\n",
    "fig, axes = plt.subplots(1,1,figsize = (3,2), dpi=300)\n",
    "plot_tree(tree_reg, feature_names=['hour'], filled=True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "viz_rmodel = dtreeviz.model(model=tree_reg, tree_index=1,\n",
    "                            X_train=X_train[['hora']], \n",
    "                            y_train=y_train, \n",
    "                            feature_names=['hora'], \n",
    "                            target_name='uso_bicis')\n",
    "viz_rmodel.view(fontname='Loma')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ver la fuente disponible, posibles problemas por fuente\n",
    "print([f.name for f in matplotlib.font_manager.fontManager.ttflist])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = tree_reg.predict(X_test[['hora']])\n",
    "metricas_evaluacion(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_train_test_predict(y_train, y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Uso de todas las variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(labels=['fecha', 'uso_bici', 'name', 'dia_nombre'], axis=1)\n",
    "y = df['uso_bici']\n",
    "print(X.shape, y.shape)\n",
    "res_split = train_test_split(X, y, random_state=22, shuffle=False)\n",
    "X_train, X_test, y_train, y_test = res_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_reg = DecisionTreeRegressor(max_depth=3)\n",
    "tree_reg.fit(X_train, y_train)\n",
    "fig, axes = plt.subplots(1,1,figsize = (5, 5), dpi=300)\n",
    "plot_tree(tree_reg, feature_names=X_train.columns, filled=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "viz_rmodel = dtreeviz.model(model=tree_reg, tree_index=1,\n",
    "                            X_train=X_train, \n",
    "                            y_train=y_train, \n",
    "                            feature_names=X_train.columns, \n",
    "                            target_name='uso_bicis')\n",
    "viz_rmodel.view(fontname='Loma')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = tree_reg.predict(X_test)\n",
    "metricas_evaluacion(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(7, 4))\n",
    "ax.plot(X_train.index, y_train)\n",
    "ax.plot(X_test.index, y_test)\n",
    "ax.plot(X_test.index, y_pred)\n",
    "fig.suptitle(\"Uso de bicicletas por estación\")\n",
    "plt.xticks(rotation=70)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_reg.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importances = pd.DataFrame(\n",
    "    tree_reg.feature_importances_, columns=[\"Importancias\"], index=X_train.columns\n",
    ")\n",
    "\n",
    "importances.sort_values('Importancias').plot(kind=\"barh\", figsize=(9, 7))\n",
    "plt.title(\"Importancias DT\")\n",
    "plt.axvline(x=0, color=\".5\")\n",
    "plt.subplots_adjust(left=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regresión lineal\n",
    "\n",
    "Dividimos los tipos de modelo de regresión en simple o múltiple.\n",
    "\n",
    "Modelo de regresión lineal es aditivo en cuanto a las variables predictoras.\n",
    "\n",
    "En casos de tener pocos ejemplos puede ser buena opción para generalizar el conocimiento.\n",
    "\n",
    "Se puede hacer transformaciones sobre las variables originales mejorando los resultados.\n",
    "\n",
    "Una de las transformaciones es la numerización de variables categóricas, como puede ser los días de la semana.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ejemplo con statsmodels, resultados con enfoque estadístico\n",
    "X_lm = sm.add_constant(X_train)\n",
    "# Ajuste MMCC\n",
    "model = sm.OLS(y_train, X_lm)\n",
    "results = model.fit()\n",
    "print(results.summary())\n",
    "\n",
    "# Predicción\n",
    "y_pred = results.predict(X_test)\n",
    "# Evaluación\n",
    "metricas_evaluacion(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quantile-Quantile plot \n",
    "f,ax = plt.subplots(1,2,figsize=(14,6))\n",
    "_,(_,_,r)= sp.stats.probplot((y_test - y_pred),fit=True,plot=ax[0])\n",
    "ax[0].set_title('Check for Multivariate Normality: \\nQ-Q Plot')\n",
    "\n",
    "#Check for Homoscedasticity\n",
    "sns.scatterplot(y = (y_test - y_pred), x= y_pred, ax = ax[1],color='r') \n",
    "ax[1].set_title('Check for Homoscedasticity: \\nResidual Vs Predicted');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regresión lineal con Scikit Learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(labels=['fecha', 'name', 'dia_nombre'], axis=1)\n",
    "X = df.loc[:, ['findesemana', 'prec', 'tamax', 'hora', 'Sunday']]\n",
    "y = df['uso_bici']\n",
    "# Transformaciones polinimicas en las variables predictoras\n",
    "# poly_features = PolynomialFeatures(degree=3, include_bias=False)\n",
    "# X = poly_features.fit_transform(X)\n",
    "print(X.shape, y.shape)\n",
    "res_split = train_test_split(X, y, random_state=22, shuffle=False)\n",
    "X_train, X_test, y_train, y_test = res_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hay disponibles otros métodos de regresión lineal: ElasticNet, BayesianRidge...\n",
    "reg = linear_model.LinearRegression().fit(X_train, y_train)\n",
    "y_pred = reg.predict(X_test)\n",
    "metricas_evaluacion(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(7, 4))\n",
    "ax.plot(X_train.index, y_train)\n",
    "ax.plot(X_test.index, y_test)\n",
    "ax.plot(X_test.index, y_pred)\n",
    "fig.suptitle(\"Uso de bicicletas por estación\")\n",
    "plt.xticks(rotation=70)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coefs = pd.DataFrame(\n",
    "    reg.coef_, columns=[\"coeficientes\"], index=X_train.columns\n",
    ")\n",
    "\n",
    "coefs.plot(kind=\"barh\", figsize=(9, 7))\n",
    "plt.title(\"Ridge\")\n",
    "plt.axvline(x=0, color=\".5\")\n",
    "plt.subplots_adjust(left=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusiones\n",
    "\n",
    "- Debe haber una experimentación buscando optimizar las métricas\n",
    "- La visualización es clave para entender el modelo y el comportamiento en la predicción"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mientorno",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
